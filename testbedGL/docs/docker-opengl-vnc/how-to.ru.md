[Английская версия](how-to.en.md)

Docker с аппаратным OpenGL через VNC
====================================

В `hexlib` теперь есть переносимая графическая оболочка, которая работает
на Windows и Linux, она использует OpenGL.

Моя цель была запустить её на Linux на удаленной машине в контейнере Docker с поддержкой аппаратного
OpenGL и доступом по VNC.

Неожиданно это оказалось не так просто.

Запуск X-server и поддержка OpenGL
----------------------------------

Чтобы запустить программу на OpenGL, нужен запущенный X-server. При этом он использует специальное
расширение для поддержки OpenGL. На десктопах это называется GLX, ещё есть
некий EGL для встроенных систем. Я пытался получить аппаратную поддержку GLX.

Я наследовал свой образ от стандартного образа `nvidia/cudagl:X.X.X`.

Одной из сложностей стал запуск X-server с аппаратной поддержкой OpenGL.
В интернете обычно советуют запустить X-server на хосте, а внутрь Docker просто
прокинуть доступ к сокету, это каталог `/tmp/.X11-unix`.

Но я хотел всё запустить внутри образа Docker и это прямо-таки стало проблемой.

Если X-server на хосте, то всё нормально, аппаратная поддержка есть.

Если же он внутри контейнера, то X-server запускается, всё хорошо, но аппаратной поддержки OpenGL нет.
Проверить можно, например, утилитой `glxinfo | grep vendor`, она выдаёт вендор MESA,
а должен быть NVIDIA. MESA — это какая-то программная эмуляция на CPU.

Единственное, что помогло — странное действие, установка драйвера NVIDIA
внутри контейнера. Пример есть в [докерфайле](./example.docker).
Очень странно, что NVIDIA уже не сделала в своём контейнере сразу всё, что нужно.
Эта установка сыпет ошибками, потому что не может перезаписать какие-то файлы.
Тем не менее, после этого действия появляется намного больше нвидиевских .so файлов,
и в результате аппаратный GLX есть.

Создание конфига xorg.conf
--------------------------

Если на машине нет физического монитора, то, чтобы запустить X-сервер,
нужно сымитировать монитор, создав специальный конфиг `xorg.conf`.

Пример создания конфига, вариант с виртуальным дисплеем:

```
sudo nvidia-xconfig -a \
    --allow-empty-initial-configuration \
    --use-display-device=None \
    --virtual=1920x1080 \
    --output-xconfig=xorg.conf
```

Работает и вариант с fake EDID:

```
sudo nvidia-xconfig -a \
    --connected-monitor=DFP-0 \
    --custom-edid=DFP-0:/etc/X11/fake_edid.hex \
    --mode-list=1920x1080 \
    --output-xconfig=xorg.conf
```

Я пробовал разные способы, но никакой разницы с точки зрения
аппаратной поддержки не заметил.

Чтобы был аппаратный GLX при запуске X-serverа внутри контейнера, помогает только
установка драйвера NVIDIA внутри контейнера (даже если она пишет ошибки).

VNC и дисплеи
-------------

Оказывается есть два варианта работы с VNC.

### Способ 1

Запустить всё на одном дисплее, и Xorg, и десктоп, и VNC. Видимо, тогда VNC-сервер
граббит экран, вот цитата:

> x0vncserver делает любой X-дисплей доступным удаленно. В отличие от Xvnc,
он не создает виртуальный дисплей. Вместо этого он просто предоставляет доступ
к существующему X-серверу (обычно тот, который подключен к физическому экрану).
XDamage будет использоваться, если существующий X-сервер поддерживает его,
в противном случае x0vncserver перейдет на опрос экрана для обнаружения изменений.

В случае с сервером TurboVNC мне не удалось так запустить.

В случае с сервером TigerVNC это удалось сделать. Но результат мне не понравился,
как будто обновляет всё же медленнее, чем при способе 2, и не поддерживает изменение
размера экрана по запросу клиента VNC.

### Способ 2

Сервер VNC создаёт свой собственный X-server для VNC.
Видимо, тогда сервер VNC перехватывает сами вызовы рисования. Вот цитата:

> Xvnc — это сервер X VNC. Он основан на стандартном сервере X, но имеет "виртуальный" экран, а не физический.
Приложения X отображают себя на нем, как если бы это был обычный дисплей X,
но доступ к ним возможен только через VNC-просмотрщик.
Таким образом, Xvnc на самом деле является двумя серверами в одном.
Для приложений это сервер X, а для удаленных пользователей VNC это сервер VNC.

Получается такая схема: VNC сервер запускает свой собственный X-server
на отдельном дисплее и именно он прокидывается по VNC.

На таком виртуальном дисплее можно запустить простой десктопный менеджер
(я пробовал LXDE и XFCE), но если запускать из него программы,
то там опять-таки нет аппаратного ускорения OpenGL!

Поэтому нужно запустить отдельный Xorg для своей программы на *другом* дисплее.

Также нужно установить пакет VirtualGL, а программу запускать вот так:

`vglrun ./myGLApp`

Turbo VNC
---------

ИИ посоветовал Turbo VNC, как самый быстрый и оптимизированный для 3D графики.
На самом деле, это довольно странная программа и всё в ней нестандартно,
начиная от установки (пример есть в [докерфайле](./example.docker)).

Тем не менее, работает она действительно неплохо. Из полезного, она использует сжатие JPEG
с настраиваемыми параметрами.

Лучше всего работает с клиентом Turbo VNC. Также удалось сделать поддержку VNC
из браузера, это называется noVNC. Работает помедленнее, но тоже ничего.

Методы сжатия:

* У него есть метод сжатия JPEG, для которого задаётся качество.
По мне, где-то 85 — это нормально. Также можно задать, делать ли сабсемплинг цветовых плоскостей,
я использую максимум 2X.

* Ещё у него есть метод сжатия CopyRect. Якобы он должен помогать, если что-то двигается без изменений,
например, перемещение окна.

* Также у него есть вид сжатия Interframe, при этом он должен сравнивать с предыдущим кадром
и пересылать только изменённые куски. Если он выключен, то он будет пересылать те куски,
которые программа перерисовывает на экране.
В случае testbedGL, это обычно целиком всё окно, так что лучше включить.
Работает этот метод тоже немного странно, по умолчанию огромными квадратами 256x256.

* Есть у него ещё понятие Lossless Refresh. Идея вроде бы хорошая — запросить кадр без потери качества.
Даже в его клиенте есть кнопка сделать Lossless Refresh. Но практика
показывает, что стоит один раз нажать эту кнопку, и после этого он всегда начинает пересылать
очень медленно и без потери качества. Также в его сервере есть опция автоматический Lossless
Refresh. Идея хорошая, например, каждые 5 секунд он присылает кадр без потери
качества. Тогда неподвижные участки рисуются хорошо, а подвижные побыстрее, со сжатием в JPEG.
Но в реальности мне не удалось добиться, чтобы это нормально работало.

Tiger VNC
---------

Этот сервер удалось запустить и в режиме перехвата существующего X-server, и в режиме
создания виртуального дисплея.

Мне понравилось больше в режиме виртуального дисплея.

Этот сервер вроде бы не такой оптимизированный, как TurboVNC, однако он как раз делает
очень нужную вещь -- в свободное время перерисовывает картинку без потери качества.

Запуск контейнера
-----------------

Контейнер запускается примерно так:

```
sudo docker run --rm \
    --net=host \
    --detach \
    --privileged \
    --runtime=nvidia \
    --name example \
```

Конечно, можно вместо `net=host` прокинуть только нужные порты.

Внутри контейнера `nvidia-smi` должна показывать наличие GPU!

После запуска выполняется такой скрипт (способ с виртуальным дисплеем):

```
export DISPLAY=:0
Xorg :0 -config xorg.conf & # сгенерированный конфиг

# TurboVNC
/opt/TurboVNC/bin/vncserver :1 -xstartup ./xstartup.sh -novnc /opt/noVNC

# TigerVNC
# tigervncserver :1 -xstartup ./xstartup.sh -PasswordFile ~/.vnc/passwd -localhost no`
```

В файле `xstartup.sh` может быть просто написано `startlxde` для десктопа LXDE.

Подключение по VNC
------------------

* Клиентом VNC, например, TurboVNC.

* Из браузера через noVNC:
`http://myhost:5801/vnc.html?host=myhost&port=5901&resize=remote&password=mypassword&autoconnect=true`
Указаны удобные опции: подстраивать размер удалённого дисплея и сразу соединяться.


